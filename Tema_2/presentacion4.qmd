---
title: 'Tema 2: Análisis multivariado de series temporales^(4)^'
subtitle: '[Curso: Tópicos Avanzados de Series Temporales](https://shuwei325.github.io/SP2600-I25)'
format: clean-revealjs
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Shu Wei Chou Chen
    url: https://shuwei325.github.io
    orcid: 0000-0001-5495-2486
    email: shuwei.chou@ucr.ac.cr
    affiliations: 
    - name: Escuela de Estadística, Universidad de Costa Rica
      url: https://www.estadistica.ucr.ac.cr/
#date: last-modified
lang: es  # español
filters:
  - reveal-auto-agenda
auto-agenda:
  bullets: numbered
  heading: Contenido
---


```{r, include=FALSE}
library(ggplot2)
library(forecast)
library(tidyverse)
library(fpp2)
library(astsa)
library(sarima)
library(car)
library(fGarch)
library(xts)
library(vars)
library(MASS)
library(MTS)
#library(dse)
```

# Procesos integrados

## Procesos integrados

Considere una serie **univariada** $X_t$. 


::: {#def-procesointegrado1}
#### Proceso integrado

Si $\nabla^d X_t$ es estacionario, decimos que $X_t$ es integrado de orden $d$, y es denotado por $X_t \sim I(d)$.
:::

::: {#exm-procesointegrado}

- Si $\nabla^d X_t \sim ARMA(p,q)$, decimos que $X_t$ es ARIMA(p,d,q), o bien $X_t \sim I(d)$.

- Cualquier serie temporal estacionaria es $I(0)$.

:::

---

Recuerde la diferenciación estacional $\nabla_s^D X_t=(1-B^s)^D X_t$


::: {#def-procesointegrado2}
#### Proceso integrado estacionalmente

Si $\nabla^d \nabla_s^D X_t$ es estacionario, decimos que $X_t$ es estacionalmente integrado de orden $d$ y $D$, y es denotado por $X_t \sim I(d,D)$.
::: 

::: {#exm-procesointegrado2}
- Si $\nabla^d \nabla_s^D X_t \sim ARMA(p,q)$, entonces $X_t$ es $SARIMA(p,d,q)(0,D,0)_s$. Decimos que $X_t \sim I(d,D)$.
:::

# Serie estacionaria por tendencia y por diferencia

## Serie estacionaria por tendencia y por diferencia

Suponga que una serie temporal $\left\lbrace X_t \right\rbrace$ es una realización de una tendencia determinística y un componente estocástico:
$$X_t=CD_t+ \eta_t,$$
donde $CD_t=\beta_0+\beta_1 t$ y $\eta_t \sim ARMA(p,q)$ que no necesariamente es estacionario e invertible, i.e., tiene su representación 
$$\phi(B)\eta_t=\theta(B)\epsilon_t$$

**Caso 1:** Si todas las raíces de $\phi(B)$ están fuera del circulo unitario, $\left\lbrace X_t \right\rbrace$ es estacionaria alrededor de una tendencia determinística. Por lo tanto, se puede eliminar la tendencia de la serie original y ajustar un modelo ARMA a los residuales. Este caso se dice que el modelo es [estacionario por tendencia (*trend-stationary*)]{.alert}.

--- 

**Caso 2:** si existe una raíz que está exactamente en el círculo unitario y el resto de las raíces están fuera del círculo unitario, i.e. $\phi(B)=(1-B)\phi^*(B)$, y $\phi^*(B)\eta_t$ es estacionario, por ende, $\left\lbrace X_t \right\rbrace$ es estacionaria por diferencia. Por lo tanto, se puede realizar diferenciación para obtener una serie estacionaria. Caso más común es cuando $d=1$. Este caso se dice que el modelo es [estacionario por diferencia (*difference-stationary*)]{.alert}.

Note que el componente del error es $I(1)$, i.e. ARIMA(p,1,q):
$$\phi^*(B)(1-B)\eta_t=\theta(B)\epsilon_t$$
Si aplicamos la diferenciación a
$$X_t=\beta_0+\beta_1 t+ \eta_t,$$
Tenemos que $\nabla X_t$ es estacionario, pues

$$X_t-X_{t-1}=\beta_0+\beta_1 t+ \eta_t - [\beta_0+\beta_1 (t-1)+ \eta_{t-1}]$$
$$=\beta_1  + [\eta_t-\eta_{t-1}]$$


## Ejemplo: Tendencia determinística y estocástica

 
```{r}
#| echo: true
autoplot(austa) + xlab("Year") +
  ylab("millions of people") +
  ggtitle("Total annual international visitors to Australia")
```

 
---

### Ajuste con tendencia determinística

```{r}
#| echo: true
trend <- seq_along(austa)
(fit1 <- auto.arima(austa, d=0, xreg=trend))
```

$$X_t=0.416+0.171t+\eta_t$$
$$\eta_t=1.113\eta_{t-1}-0.380 \eta_{t-2}+\epsilon_t$$
$$\epsilon_t \overset{iid}{\sim} N(0,0.03)$$


---

### Ajuste con tendencia estocástica

```{r}
#| echo: true
(fit2 <- auto.arima(austa, d=1))
``` 

$$X_t-X_{t-1}=0.173+\eta'_t,$$
o de otra forma,

$$X_t=X_0+0.173t+\eta_t$$
$$\eta_t=\eta_{t-1}+0.301\epsilon_{t-1}+\epsilon_t$$
$$\epsilon_t \overset{iid}{\sim} N(0,0.034)$$


---


```{r}
#| echo: true
fc1 <- forecast::forecast(fit1,
  xreg = length(austa) + 1:10)
fc2 <- forecast::forecast(fit2, h=10)
autoplot(austa) +
  autolayer(fc2, series="Stochastic trend") +
  autolayer(fc1, series="Deterministic trend") +
  ggtitle("Forecasts from trend models") +
  xlab("Year") + ylab("Visitors to Australia (millions)") +
  guides(colour=guide_legend(title="Forecast"))+
  theme_bw()+ theme(legend.position="top")
``` 



## Serie estacionaria por tendencia y por diferencia

- Ejemplo de estos dos tipos de estacionariedad:

[Tendencia determinística:]{.alert}
$$X_t=X_{t-1}+\mu=X_0+\mu t$$
[Tendencia estocástica (acumulación de choques aleatorias):]{.alert}
$$X_t=X_{t-1}+\epsilon_t=X_0+\sum_{s=1}^t \epsilon_s$$
donde $\mu$ es una constante y $\epsilon_t$ es ruido blanco.

---

- En síntesis, una serie temporal $\left\lbrace X_t \right\rbrace$ está compuesto por una tendencia determinística y un componente estocástico $\eta_t$ que es modelado por $ARIMA(p,d,q)$.
- Se puede descomponer $\eta_t$ en dos componentes: tendencia estocástica (choques aleatorios) y el componente aleatorio "estacionario". 
- Entonces, $\left\lbrace X_t \right\rbrace$ se puede descomponer en tres componentes:
  1. tendencia determinística,
  2. tendencia estocástica, y
  3. el componente "aleatorio".

- Un modelo estacionario por tendencia, no tiene la tendencia estocástica, y el componente aleatorio es $ARMA(p,q)$.
- En el caso de un modelo estacionario por diferencia, el polinomio autoregresivo del componente $\eta_t$ tiene al menos una raíz unitaria.

---

:::: {.columns}

::: {.column width="50%"}
```{r}
set.seed(123456)
e <- rnorm(200)
## pure random walk
rw.nd <- cumsum(e)
## trend
trd <- 1:200
## random walk with drift
rw.wd <- 0.3*trd + cumsum(e)
## deterministic trend and noise
dt <- e + 0.3*trd
## plotting
plot.ts(dt, lty=1, col=1)
lines(rw.wd, lty=2, col= 2)
legend("topleft", legend=c('tend. det.. + ruido',
                   'tend. det. + tend. estoc.'),
       lty=c(1, 2),col=c(1,2)) 
```

:::

::: {.column width="50%"}

```{r echo=FALSE, out.width = "100%", fig.align="center"}
plot.ts(rw.nd)
legend("topright", legend=c( 'tend. estocast.')) 
```

:::
::::

---

- Vimos que si una serie temporal $\left\lbrace X_t \right\rbrace$ se puede descomponer en tres componentes: (1) tendencia determinística, (2) tendencia estocástica, y (3) el componente "aleatorio", i.e.,
$$
X_t=CD_t+ \eta_t,
$$
donde $CD_t=\beta_0+\beta_1 t$ y $\eta_t \sim ARMA(p,q)$ que no necesariamente es estacionario e invertible, i.e., tiene su representación 
$$\phi(B)\eta_t=\theta(B)\epsilon_t$$
- Si existe una raíz que está exactamente en el círculo unitario y el resto de las raíces están fuera del círculo unitario, i.e. $\phi(B)=(1-B)\phi^*(B)$, y $\phi^*(B)\eta_t$ es estacionario. Por lo tanto, $\left\lbrace X_t \right\rbrace$ es estacionaria por diferencia. Por lo tanto, se puede realizar diferenciación para obtener una serie estacionaria. 
- El modelo se puede representar como
$$X_t=CD_t+ \eta_t,$$
$$\phi^*(B)(1-B)\eta_t=\theta(B)\epsilon_t$$
# El contraste de raíz unitaria
 
## El contraste de raíz unitaria

Para investigar si el proceso:
$$\eta_t=X_t-CD_t,$$
contiene raíz unitaria, Dickey Fuller (1979) propuso la prueba de DF de la siguiente forma:


- Suponiendo que $\eta_t$ es un AR(1):

$$\eta_t=\phi_1 \eta_{t-1}+a_t$$
- Si se toma una diferencia:

$$\nabla \eta_t=\eta_t-\eta_{t-1}=\phi_1 \eta_{t-1}+a_t-\eta_{t-1}=(\phi_1-1) \eta_{t-1}+a_t=\pi \eta_{t-1}+a_t$$

Se puede obtener el estimador del mínimo cuadrado de $\hat{\pi}^*$ mediante una regresión ordinaria de $\nabla \eta_t$ sobre $\eta_{t-1}$. 
Por lo tanto, el contraste para la estacionariedad se puede formular mediante las siguientes hipótesis:
$$H_0: \phi_1=1 ~~\text{v.s.}~~ H_1: \phi_1<1$$

 
## El contraste de raíz unitaria

- De la diapositiva anterior,

$$\nabla \eta_t=\eta_t-\eta_{t-1}=\phi_1 \eta_{t-1}+a_t-\eta_{t-1}=(\phi_1-1) \eta_{t-1}+a_t=\pi \eta_{t-1}+a_t$$

La idea es obtener el estimador del mínimo cuadrado de $\hat{\pi}$ mediante una regresión ordinaria de $\nabla \eta_t$ sobre $\eta_{t-1}$. 
Por lo tanto, el contraste para la estacionariedad se puede formular mediante las siguientes hipótesis:
$$H_0: \phi_1=1 ~~\text{v.s.}~~ H_1: \phi_1<1$$
o equivalentemente a:
$$H_0: \pi=0 ~~\text{v.s.}~~ H_1: \pi<0$$

 
## El contraste de raíz unitaria

- El contraste se puede realizar mediante la estadística $\hat{\tau}$ de Dickey-Fuller:

$$\hat{\tau}=\frac{\hat{\pi}^*}{e.e.(\hat{\pi}^*)}.$$
- La distribución de $\hat{\tau}$ no es conocida y se obtiene los percentiles y los valores críticos de la distribución de $\hat{\tau}$ por medio de simulaciones.
- Si se rechaza la $H_0$, la serie es estacionaria.
- Si no se rechaza la $H_0$, la serie es no estacionaria, y se tiene que:
$$\eta_t-\eta_{t-1}=a_t,$$
la cual es denominada **camino aleatorio**.


 
## El contraste de raíz unitaria

- El procedimiento anterior realiza la prueba después de remover el componente de tendencia determinística $CD_t$, y además, considera un caso simple de AR(1).

- Se puede generalizar el procedimiento anterior involucrando la tendencia determinística y el componente aleatorio de AR(p) y es llamado como **prueba de Dickey-Fuller aumentado**. Considere

$$\nabla X_t= \tau' DR_t +  \pi X_{t-1} + \sum_{j=1}^{k} \gamma_j \nabla X_{t-j} +a_t,~~\text{con}~~ k=p-1$$
para asegurar que la correlación serial en el error es removido.

- Este procedimiento involucra un valor $k$ predeterminado.


 
## El contraste de raíz unitaria

- Considere el caso de una tendencia lineal:
$$\nabla X_t= \beta_0 + \beta_1 t +  \pi X_{t-1} + \sum_{j=1}^{k} \gamma_j \nabla X_{t-j} +a_t,~~\text{con}~~ k=p-1$$
para asegurar que la correlación serial en el error es removido.

**Paso 1**: Probar $H_0: \pi=0$ (con el estadístico $\tau$)
  - Si se rechaza $H_0$, entonces no hay raíz unitaria.

**Paso 2**: Si $\pi = 0$, probar $H_0: \beta_1=\pi=0$ (con el estadístico $\Phi_3$).
  - Si no se rechaza $H_0$, entonces no hay tendencia y contiene raíz unitaria.
  - Si se rechaza $H_0$, hay tendencia y contiene raíz unitaria.
  
 
## Ejemplo: La serie de consumo

La serie del índice de consumo en Reino Unido del cuarto trimestre, 1966 al segundo trimestre de 1991.

:::: {.columns}

::: {.column width="50%"}
```{r echo=FALSE, fig.align="center", out.width = "100%"}
data(Raotbl3)
lc <- ts(Raotbl3$lc, start=c(1966,4), end=c(1991,2), frequency=4)
plot(lc)
```
:::

::: {.column width="50%"}
```{r echo=FALSE, fig.align="center", out.width = "100%"}
acf(lc)
```
:::
::::


 
## Ejemplo: La serie de consumo


- En R, aparece una tabla similar a esa:

| Statistics | 1pct  | 5pct   | 10pct | test-statistics |
|   --| --|   |  |
| tau3       | -4.04 | -3.45 | -3.15 |  -2.2389  |
| phi2       |   6.50 | 4.88 |  4.16 | 3.7382 |
| phi3       | 8.73 | 6.49  | 5.47 |  2.5972 |

- Vamos a ver con más detalle las salidas de R en el laboratorio.

**Paso 1**: Probar $H_0: \pi=0$ (con el estadístico $\tau$)
  - Usando un 5% de significancia, note que el valor crítico es $-3.45<-2.2389$ el estadístico $\tau$. Por lo tanto, no se rechaza $H_0$.

 
## Ejemplo: La serie de consumo


- En R, aparece una tabla similar a esa:

| Statistics | 1pct  | 5pct   | 10pct | test-statistics |
|   --| --|   |  |
| tau3       | -4.04 | -3.45 | -3.15 |  -2.2389  |
| phi2       |   6.50 | 4.88 |  4.16 | 3.7382 |
| phi3       | 8.73 | 6.49  | 5.47 |  2.5972 |

**Paso 2**: Dado que $\pi=0$, probamos $H_0: \beta_1=\pi=0$ (con el estadístico $\Phi_3$).
  - Note que el estadístico $F$= $2.5972<6.49$ el valor crítico. Por lo tanto, no se rechaza $H_0$.
  - Se concluye que el modelo no tiene tendencia, y con raíz unitaria.  
  
**Paso 3**: Ya que la serie contiene raíz unitaria, se realiza diferenciación para analizarlo.

 
## Ejemplo: La serie de consumo

La serie diferenciada:

:::: {.columns}

::: {.column width="50%"}
```{r echo=FALSE, fig.align="center", out.width = "100%"}
lc.dif <- diff(lc)
plot(lc.dif)
```
:::

::: {.column width="50%"}
```{r echo=FALSE, fig.align="center", out.width = "100%"}
acf(lc.dif)
```
:::
::::
 
## Otros contrastes de raíz unitaria

- Prueba de Phillips-Perron
- Prueba de Elliott-Rothenberg-Stock
- Prueba de Schmidt-Phillips
- Prueba de Kwiatkowski-Phillips-Schmidt-Shin


	
 
## En la próxima clase veremos

### Procesos cointegrados


