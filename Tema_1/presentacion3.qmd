---
title: 'Tema 1: Análisis espectral de series temporales-3'
subtitle: 'Curso: Tópicos Avanzados de Series Temporales'
format: clean-revealjs
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Shu Wei Chou Chen
    #orcid: 0000-0001-5495-2486
    email: shuwei.chou@ucr.ac.cr
    affiliations: Escuela de Estadística, Universidad de Costa Rica
#date: last-modified
lang: es  # español
---


```{r, include=FALSE}
library(ggplot2)
library(forecast)
library(fpp2)
library(astsa)
library(tidyverse)
```



En la clase anterior vimos:

1. Introducción
2. Ejemplos de motivación
3. Comportamiento cíclico y periodicidad.
4. Estimación y periodograma.

 
## Contenido

<ol start="10">

5. Función de densidad espectral. <br>
6. Representación espectral de procesos estacionarios <br>
7. Periodograma y la Transformada Discreta de Fourier<br>
8. Estimación de periodograma.<br>
</ol>

 
## Representación espectral

- Es necesario entender los fundamentos teóricos de los conceptos de frecuencia (poblacional) antes de entrar al caso cuando se tiene series observadas (muestral).

- Empezamos a definir la densidad espectral y su relación con un proceso estacionario.

 
## Representación espectral


**Propiedad 1: Representación espectral de una función de autocovariancia**

Si $\left\lbrace x_t \right\rbrace$ es estacionario con función de autocovariancia $\gamma(h)=Cov(x_{t+h},x_t)$, entonces existe una única función monótonamente creciente $F(\omega)$, llamada **función de distribución espectral**, con 
- $F(-\infty)=F(-1/2)=0$, y 
- $F(\infty)=F(1/2)=\gamma(0)$

tal que

$$\gamma(h)= \int_{-\frac{1}{2}}^{\frac{1}{2}} e^{2\pi i\omega h} dF(\omega)$$

**Nota:** Esta propiedad usa el concepto de integral de Riemann-Stieltjes (ver C.4, Shumway & Stoffer). Cuando la función de autocovariancia es absolutamente sumable, esa función de distribución espectral es absolutamente continua con $dF(\omega)=f(\omega)d\omega$.


 
## Representación espectral

**Propiedad 2: Densidad espectral**

Si la función de autocovariancia $\gamma(h)$, de un proceso estacionario satisface la condición
$$\sum_{h=-\infty}^{\infty} |\gamma(h)|< \infty$$
entonces tiene la representación
$$\gamma(h)= \int_{-\frac{1}{2}}^{\frac{1}{2}} e^{2\pi i\omega h} f(\omega)d\omega,~~~ h=0,\pm 1,\pm 2,...$$
y la transformación inversa de la densidad espectral
$$f(\omega) = \sum_{h=-\infty}^{\infty} \gamma(h) e^{-2 \pi i \omega h}, ~~~~~~ -\frac{1}{2} \leq \omega \leq \frac{1}{2}$$
 
## Representación espectral

Algunas propiedades de la densidad espectral:

- $f(\omega) \geq 0$ para todo $\omega$,

debido a que $\gamma(h)$ es definida no negativa.

- $f(\omega)=f(-\omega)$

- $\gamma(0)= Var(x_t) = \int_{-\frac{1}{2}}^{\frac{1}{2}} f(\omega)d\omega$

**Nota:** 
- La función de autocovariancia y la función de distribución espectral contiene la misma información.
- La FAC expresa la información en término de rezagos (tiempo), mientras que la distribución espectral expresa la misma información en término de ciclos (frecuencias).

 
## Ruido blanco

:::: {.columns}

::: {.column width="50%"}
- Una colección de variables aleatorias no correlacionadas, $w_t$, con media 0 y variancia $\sigma_w^2$, denotado por $w_t \sim wn(0,\sigma_w^2)$.

- La FAC está dada por:

$$
\gamma_w(h)=\left\lbrace 
\begin{aligned}
\sigma_w^2, & & h = 0 \\
0, & &  h \neq 0.
\end{aligned}
\right. 
$$
- Su densidad espectral está dada por:
$$f_w(\omega)=\sigma_w^2,$$
para $-1/2 \leq \omega \leq 1/2$.

:::

::: {.column width="50%"}

- Simulación de una colección de $w_t \sim N(0,1)$ con $T=500$.

```{r echo=FALSE, out.width = "90%"}
w = rnorm(500,0,1) 
plot.ts(w, main="")
```
:::
::::

 
## Proceso lineal

- Como un proceso lineal es una herramienta que engloba varios modelos de series estacionarias (ej: ARMA), es importante presentar los resultados teóricos correspondientes. 

- Un filtro lineal utiliza coeficientes $a_j, j=0,\pm1,...$, para transformar una serie *input* $x_t$ a una serie *ouput* $y_t$:

$$y_t=\sum_{j=-\infty}^{\infty}a_j x_{t-j},~~~ \sum_{j=-\infty}^{\infty}|a_j| < \infty.$$

 
## Proceso lineal

**Propiedad: El espectro de una serie estacionaria filtrada**

Si $f_X(\omega)$ es la densidad espectral de $x_t$, una serie estacionaria. Entonces, la densidad espectral $f_Y(\omega)$ de la serie filtrada (output) está dada por:
$$f_Y(\omega)=|A(\omega)|^2 f_X(\omega),$$
donde 
$$A(\omega)=\sum_{j=-\infty}^{\infty} a_j e^{-2\pi i \omega j}$$
es llamada la función respuesta de frecuencia.

**Nota:** $A(\omega)$ es la transformada discreta de Fourier de $a_j$.


 
## Proceso lineal

Un proceso ARMA es un caso particular de un proceso lineal. Recuerde que un proceso ARMA(p,q) se define como:

$$x_t=\phi_1 x_{t-1}+\phi_2 x_{t-2}+...+\phi_p x_{t-p}$$
$$+w_t-\theta_1 w_{t-1}-\theta_2 w_{t-2}-...-\theta_q w_{t-q}$$

Utilizando los operadores de rezagos, el ARMA(p,q) se puede escribir como

$$\phi(B)x_t=\theta(B)w_t,$$
donde:<br /> 
$\phi(B)=1-\phi_1 B -\phi_2  B^2-...-\phi_p B^p$ es **el operador autoregresivo**.<br /> 
$\theta(B)=1-\theta_1 B-\theta_2 B^2-...-\theta_q B^q$ es **el operador de medias móviles**.

 
## Proceso lineal

Un proceso ARMA(p,q) estacionario e invertible se puede escribir como:

$$x_t=\phi(B)^{-1}\theta(B)w_t,$$

**Propiedad: La densidad espectral de un modelo ARMA**


Si $x_t$ es ARMA(p,q):


Su densidad espectral es dada por

$$f_X(\omega)=\sigma_w^2 \frac{|\theta(e^{-2 \pi i \omega})|^2}{|\phi(e^{-2 \pi i \omega})|^2}.$$
 
## Ejemplos

**MA(1):**
- Considere $X_t=w_t+0.5 w_{t-1}$. 
- El operador de medias móviles es $\theta(B)=1+0.5 B$.
- Entonces, 


$$f_X(\omega)=\sigma_w^2 |\theta(e^{-2 \pi i \omega})|^2$$
$$=\sigma_w^2 |1+0.5 e^{-2 \pi i \omega}|^2$$
$$=\sigma_w^2 (1+0.5 e^{-2 \pi i \omega})(1+0.5 e^{2 \pi i \omega})$$
$$=\sigma_w^2 \left[1.25 + 0.5 (e^{-2 \pi i \omega}+e^{2 \pi \omega})\right]$$
 
## Ejemplos

**AR(2):**
- Considere $X_t-X_{t-1}+0.9X_{t-2}=w_t$. 
- El operador autorregresivo es $\phi(B)=1-B+0.9 B^2$.
- Entonces, 
$$|\phi(e^{-2 \pi i \omega})|^2=(1-e^{-2 \pi i \omega}+0.9 e^{-4 \pi i \omega})(1-e^{2 \pi i \omega}+0.9 e^{4 \pi i \omega})$$
$$=2.81-3.8 cos(2\pi\omega)+1.8 cos(4\pi\omega).$$
- De esta forma, 

$$f_X(\omega)=\sigma_w^2 \frac{1}{2.81-3.8 cos(2\pi\omega)+1.8 cos(4\pi\omega)}.$$

 
## Ejemplos

```{r echo=FALSE, out.width = "70%", fig.align="center"}
par(mfrow=c(2,2))
arma.spec(main="Ruido blanco", col=4)
arma.spec(ma=.5, main="MA(1)", col=4)
arma.spec(ar=c(1,-.9), main="AR(2)", col=4)
```

 
## Periodograma y la Transformada Discreta de Fourier

- A continuación, presentamos los conceptos equivalentes de la representación espectral pero al caso de series temporales observadas de forma discreta.

- Sea $x_1,...,x_T$ una serie temporal observada. Defina la **Transformada Discreta de Fourier (DFT)**:
$$d(\omega_j)=T^{-1/2}\sum_{t=1}^T x_t e^{-2 \pi i \omega_j t},~~~ \text{para}~ j=0,1,...,T-1,$$
donde frecuencias $\omega_j=j/n$ son llamadas frecuencias fundamentales o de Fourier.

- DFT requiere $T^2$ operaciones complejas. Cuando $T$ es grande, es más factible usar la Transformada Rápida de Fourier (FFT), propuesta por Cooley y Tukey que requiere únicamente $T ln T$ operaciones.


 
## Periodograma y la Transformada Discreta de Fourier

- Esta transformada es una transformación lineal uno a uno, i.e.

- Dada $x_1,...,x_T$ una serie temporal observada. Su **Transformada Discreta de Fourier (DFT)** es dada por:
$$d(\omega_j)=T^{-1/2}\sum_{t=1}^T x_t e^{-2 \pi i \omega_j t},~~~ \text{para}~ j=0,1,...,T-1,$$

- Se puede definir la DFT inversa

$$x_t=T^{-1/2}\sum_{t=1}^{T-1} d(\omega_j) e^{2 \pi i \omega_j t},~~~ \text{para}~~ t=1,...,T.$$
 
## Periodograma y la Transformada Discreta de Fourier

- Sea $x_1,...,x_T$ una serie temporal observada. Defina el **periodograma**:

$$I(\omega_j)=|d(\omega_j)|^2,~~~ \text{para}~ j=0,1,...,T-1,$$
- Se puede comprobar que:

$$I(\omega)=|d(\omega_j)|^2=\sum_{h=-(T-1)}^{T-1} \hat{\gamma}(h) e^{-2 \pi i \omega_j h},~~~ \text{para}~~ t= 1,...,T,$$
donde $\hat{\gamma}(h)$ es la función de autocovariancia muestral.
- Se puede interpretar el periodograma como la densidad espectral muestral de $x_t$.


 
## Propiedades del periodograma

- Se puede comprobar que:

$$E[I(\omega_j)]=\sum_{h=-(T-1)}^{T-1} \frac{T-|h|}{T} \gamma(h) e^{-2 \pi i \omega_j h}.$$

- Además, cuando $T \rightarrow \infty$, 


$$E[I(\omega_{j:T})] \rightarrow f(\omega)=\sum_{h=-\infty}^{\infty} \gamma(h) e^{-2 \pi i h \omega},$$
donde $\omega_{j:T}=j_T/T$ es una secuencia que tiende a $\omega$.

 
## Propiedades del periodograma
**Propiedad: Distribución del periodograma**

- Sea
$$x_t=\sum_{j=-\infty}^\infty \psi_j w_{t-j},~~~~~\sum_{j=-\infty}^\infty |\psi_j| < \infty,$$
donde $w_t \sim iid(0,\sigma_w^2)$. Si $\sum_{h=-\infty}^\infty |h| |\gamma(h)| < \infty$, entonces para cualquier colección de $m$ frecuencias distintas $\omega_j \in \{0,1/2\}$ con $\omega_{j:T}\rightarrow \omega_j$

$$\frac{2 I(\omega_{j:T})}{f(\omega_j)} \rightarrow \chi^2_2.$$
 

- Como consecuencia, se puede construir un intervalo de confianza de $100(1-\alpha)\%$, con
$$\frac{2 I(\omega_{j:T})}{\chi^2_2(1-\alpha/2)}<f(\omega)<\frac{2 I(\omega_{j:T})}{\chi^2_2(\alpha/2)}$$

## Consideraciones importantes

- En la práctica, es común encontrar series con tendencias.
- La presencia de tendencias produce frecuencias bajas extremas que ocultan la apariencia de frecuencias altas.
- Por lo tanto, se debe eliminar la tendencia utilizando algún método (regresión lineal, cuadrática, medias móviles, etc.)



 
## Ejemplo: El Niño y la población de peces (SOI y reclutamiento)

- Se tiene la serie ambiental de índice de oscilación del sur (SOI, *Southern Oscillation Index*), y la serie de número de peces nuevos (Reclutamiento) de 453 meses de 1950 a 1987.
- SOI mide cambios en presión relacionada a la temperatura del superficie del mar en el oceano pacífico central, el cual se calienta cada 3-7 años por el efecto El Niño.

```{r echo=FALSE,warning=FALSE, message=FALSE, fig.align="center", out.width = "40%"}
par(mfrow = c(2,1))  # set up the graphics
tsplot(soi, ylab="", main="SOI")
tsplot(rec, ylab="", main="Reclutamiento") 
```



 
## Ejemplo: SOI y reclutamiento 

:::: {.columns}

::: {.column width="50%"}

- El eje X muestra múltiplos de $\Delta=\frac{1}{12}$.
- Ambos periodogramas muestran el principal pico cuando $\omega=1\Delta=\frac{1}{12}$.
- Además, una posible potencia alrededor de $\omega=\frac{1}{4}\Delta=\frac{1}{48}.$, representando el efecto del Niño que tiene la característica de tener el ciclo irregular.
:::

::: {.column width="50%"}
```{r echo=FALSE, fig.align="center", out.width = "100%"}
par(mfrow=c(2,1))
soi.per = mvspec(soi)             
abline(v=1/4, lty="dotted")
rec.per = mvspec(rec) 
abline(v=1/4, lty="dotted")
```
:::
::::


## Ejemplo: SOI y reclutamiento 
```{r}
head(soi.per$details) 
```


```{r}
tail(soi.per$details) 
```

- Recuerde que el dominio de frecuencia es $(0,0.5)$. El gráfico muestra las frecuencias transformadas que debe multiplicar por $12$, y por lo tanto, $(0 \times 12, 0.5 \times 12)$.

 
## Ejemplo: SOI y reclutamiento 

- Las frecuencias más importantes:

```{r}
soi.per$details[c(10,40),] 
```


 
## Ejemplo: SOI y reclutamiento 

- Recordando la propiedad del periodograma, se puede construir un intervalo de confianza de $100(1-\alpha)\%$, con
$$\frac{2 I(\omega_{j:T})}{\chi^2_2(1-\alpha/2)}<f(\omega)<\frac{2 I(\omega_{j:T})}{\chi^2_2(\alpha/2)}$$

```{r}
U = qchisq(.025,2)
L = qchisq(.975,2)
# para frecuencia= 1/4
c(2*soi.per$spec[10]/L,2*soi.per$spec[10]/U)
# para frecuencia= 1
c(2*soi.per$spec[40]/L,2*soi.per$spec[40]/U)
```

 
## Ejemplo: SOI y reclutamiento 

- ¡Note que el intervalo es muy amplio y **la incertidumbre es muy grande**!

- De hecho, recordemos que:

$$\frac{2 I(\omega_{j:T})}{f(\omega_j)} \rightarrow \chi^2_2.$$


$\Rightarrow E\left[I(\omega)\right] \approx f(\omega)$ y $Var\left[I(\omega)\right] \approx f^2(\omega)$.

- Es decir, el periodograma no es un estimador consistente de la densidad espectral, i.e.

$$Var\left[I(\omega)\right] \nrightarrow 0 ~~\text{cuando} ~~n \rightarrow \infty.$$
- La solución es utilizar un **periodograma suavizado**

 
## En la próxima clase veremos


<ol start="9">
9. Estimaciones en el dominio de frecuencia.<br>
<p style="margin-left: 25px;">  &#9702; Estimación espectral no paramétrica </p>
<p style="margin-left: 25px;">  &#9702; Estimación espectral paramétrica </p> <br>
  
10. Aplicaciones del análisis espectral.<br>
</ol>

